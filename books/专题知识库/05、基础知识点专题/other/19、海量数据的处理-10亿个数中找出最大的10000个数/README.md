# 海量数据的处理-10亿个数中找出最大的10000个数

## top K问题
在大规模数据处理中，经常会遇到的一类问题：在海量数据中找出出现频率最好的前k个数，
或者从海量数据中找出最大的前k个数，这类问题通常被称为top K问题。
例如，在搜索引擎中，统计搜索最热门的10个查询词；在歌曲库中统计下载最高的前10首歌等。

针对top K类问题，通常比较好的方案是**分治+Trie树/hash+小顶堆（就是上面提到的最小堆）**，
即先将数据集按照Hash方法分解成多个小数据集，然后使用Trie树活着Hash统计每个小数据集中的query词频，
之后用小顶堆求出每个数据集中出现频率最高的前K个数，最后在所有top K中求出最终的top K。


## 有1亿个浮点数，如果找出期中最大的10000个
    
- 最容易想到的方法是将数据全部排序                                                              
然后在排序后的集合中进行查找，最快的排序算法的时间复杂度一般为O（nlogn），如快速排序。
但是在32位的机器上，每个float类型占4个字节，1亿个浮点数就要占用400MB的存储空间，
对于一些可用内存小于400M的计算机而言，很显然是不能一次将全部数据读入内存进行排序的。

- 第二种方法为局部淘汰法                                               
该方法与排序方法类似，用一个容器保存前10000个数，然后将剩余的所有数字——与容器内的最小数字相比，
如果所有后续的元素都比容器内的10000个数还小，那么容器内这个10000个数就是最大10000个数。
如果某一后续元素比容器内最小数字大，则删掉容器内最小元素，并将该元素插入容器，最后遍历完这1亿个数，
得到的结果容器中保存的数即为最终结果了。此时的时间复杂度为O（n+m^2），其中m为容器的大小，即10000。

- 第三种方法是分治法                                                 
将1亿个数据分成100份，每份100万个数据，找到每份数据中最大的10000个，最后在剩下的100*10000个数据里面找出最大的10000个。

- 第四种方法是Hash法                                                               
如果这1亿个书里面有很多重复的数，先通过Hash法，把这1亿个数字去重复，这样如果重复率很高的话，会减少很大的内存用量，
从而缩小运算空间，然后通过分治法或最小堆法查找最大的10000个数。

- 第五种方法采用最小堆                                                
